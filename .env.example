# Ollama Configuration
OLLAMA_MODEL=qwen2.5:0.5b
OLLAMA_BASE_URL=http://localhost:11434

# LangSmith Tracing (Optional - for debugging)
# Get your API key from https://smith.langchain.com
# LANGSMITH_TRACING=true
# LANGSMITH_ENDPOINT=https://api.smith.langchain.com
# LANGSMITH_API_KEY=your-api-key-here
# LANGSMITH_PROJECT=ai-doc-rag-local
